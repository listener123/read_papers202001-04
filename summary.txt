简单整理了一下从1月到现在接触到的论文，主要与目标检测相关也有一些别的领域工作。做一总结，梳理一下思路，方便之后形成研究方向。以完整的目标检测过程串联这些论文，记录可产生研究点的内容并附自己阅读实验感受。

数据集：
常用标准集是COCO、MS COCO、VOC

预处理：
数据增强trick[1] 
感受：这部分工作对于提升性能很有效，不过现有的方法已经比较充分了，以及这部分研究的实验成本较大。
弱监督 scale match[2] 
感受：这部分研究比较跨界，比如[2]是把标准数据集进行直方调整适应目标数据集实现训练集扩充，在讲座中也听到过迁移学习、先验语义特征的one-shot、zero-shot等等。这类研究比较新颖，贴近实际应用。没有试验过，不太清楚难度有多大。
频域学习 [3] 
感受：这是比较特殊的一篇，算是另辟蹊径。

主干网络：
金字塔FPN [4][5][6]
注意力系列网络[7]
感受：这两类研究是比较吸引人的。他们比较注重设计的意义，解释性比较好，多以各种角度的融合算法作为核心。一般会联系到下一阶段的关键点和loss的设计。
模块改造设计[8][9][10][11][12] 
感受：这部分分为两大类，一类是产自视觉类别的比赛，另一类是大厂或业内的大IP进行革新。他们更注重是如何设计实现的，讨论遇到的问题，使用他们的设计可以从结果上看解决问题，解释较少或只是用数据说话。

检测算法：
Loss设计
分类任务 正负例[13]
回归任务 关键点[7][14][15]
感受：这部分也是注重可解释性，我认为是影响目标检测精度的第二个关键因素，第一个是主干网络的提取特征能力。这部分实验复现的较多一点，感觉难点在于一些实现细节，算法很容易失效，基本上只有照搬源码才能有效。这是因为它最终只会输出一个值用于整个网络十几万或更多参数的更新，小的变化就可能造成大偏差。这部分研究需要较好的数学功底，可能设计的想法是好的，但是要没有配套的loss代价公式，也不能体现出效果。

评价体系：
精度mAP、计算开销FLOPs、GOP、实际运行花销FPS（这里说法不确定准确）
感受：这一部分是所有研究的最终落脚点。精度基本统一比较的是各种阈值下的mAP，有少部分针对性比较强的工作，会讨论误判率（针对密集检测）、准确率（针对分类问题）、IOU（针对回归问题）。运行能力方面，感觉大方向在偏向实际运行花销，有一篇论文很直白的指出计算开销不具有实际参考价值[12]。不过在iresnet[11]中还是有提到每个模块的FLOPs进行理论讨论。
